#
# Module providing the `Pool` class for managing a process pool
#
# multiprocessing/pool.py
#
# Copyright (c) 2006-2008, R Oudkerk
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
# 3. Neither the name of author nor the names of any contributors may be
#    used to endorse or promote products derived from this software
#    without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
# OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
# OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
# SUCH DAMAGE.
#

__all__ = ['Pool'];

#
# Imports
#

import threading;
import Queue;
import itertools;
import collections;
import time;

from multiprocessing import Process, cpu_count, TimeoutError;
from multiprocessing.util import Finalize, debug;

#
# Constants representing the state of a pool
#

RUN = 0;
CLOSE = 1;
TERMINATE = 2;

#
# Miscellaneous
#

job_counter = itertools.count();

function mapstar(args){
    return map(*args);

#
# Code run by worker processes
#

}
class MaybeEncodingError(Exception){
    """Wraps possible unpickleable errors, so they can be
    safely sent through the socket.""";

    function __init__( exc, value){
        this.exc = repr(exc);
        this.value = repr(value);
        super(MaybeEncodingError, this).__init__(this.exc, this.value);

    }
    function __str__(){
        return "Error sending result: '%s'. Reason: '%s'" % (this.value,
                                                             this.exc);

    }
    function __repr__(){
        return "<MaybeEncodingError: %s>" % str(this);


}
} function worker(inqueue, outqueue, initializer=nil, initargs=(), maxtasks=nil){
    assert maxtasks is nil or (type(maxtasks) in (int, long) and maxtasks > 0);
    put = outqueue.put;
    get = inqueue.get;
    if hasattr(inqueue, '_writer'){
        inqueue._writer.close();
        outqueue._reader.close();

    }
    if initializer is not nil{
        initializer(*initargs);

    }
    completed = 0;
    while maxtasks is nil or (maxtasks and completed < maxtasks){
        try{
            task = get();
        } except (EOFError, IOError){
            debug('worker got EOFError or IOError -- exiting');
            break;

        }
        if task is nil{
            debug('worker got sentinel -- exiting');
            break;

        }
        job, i, func, args, kwds = task;
        try{
            result = (true, func(*args, **kwds));
        } except Exception, e{
            result = (false, e);
        } try{
            put((job, i, result));
        } except Exception as e{
            wrapped = MaybeEncodingError(e, result[1]);
            debug("Possible encoding error while sending result: %s" % (
                wrapped));
            put((job, i, (false, wrapped)));

        }
        task = job = result = func = args = kwds = nil;
        completed += 1;
    } debug('worker exiting after %d tasks' % completed);

#
# Class representing a process pool
#

}
class Pool(object){
    '''
    Class which supports an async version of the `apply()` builtin
    ''';
    Process = Process;

    function __init__( processes=nil, initializer=nil, initargs=(),
                 maxtasksperchild=nil){
        this._setup_queues();
        this._taskqueue = Queue.Queue();
        this._cache = {};
        this._state = RUN;
        this._maxtasksperchild = maxtasksperchild;
        this._initializer = initializer;
        this._initargs = initargs;

        if processes is nil{
            try{
                processes = cpu_count();
            } except NotImplementedError{
                processes = 1;
        } } if processes < 1{
            raise ValueError("Number of processes must be at least 1");

        }
        if initializer is not nil and not hasattr(initializer, '__call__'){
            raise TypeError('initializer must be a callable');

        }
        this._processes = processes;
        this._pool = [];
        this._repopulate_pool();

        this._worker_handler = threading.Thread(
            target=Pool._handle_workers,
            args=(this, )
            );
        this._worker_handler.daemon = true;
        this._worker_handler._state = RUN;
        this._worker_handler.start();


        this._task_handler = threading.Thread(
            target=Pool._handle_tasks,
            args=(this._taskqueue, this._quick_put, this._outqueue,
                  this._pool, this._cache)
            );
        this._task_handler.daemon = true;
        this._task_handler._state = RUN;
        this._task_handler.start();

        this._result_handler = threading.Thread(
            target=Pool._handle_results,
            args=(this._outqueue, this._quick_get, this._cache)
            );
        this._result_handler.daemon = true;
        this._result_handler._state = RUN;
        this._result_handler.start();

        this._terminate = Finalize(
            this, this._terminate_pool,
            args=(this._taskqueue, this._inqueue, this._outqueue, this._pool,
                  this._worker_handler, this._task_handler,
                  this._result_handler, this._cache),
            exitpriority=15
            );

    }
    function _join_exited_workers(){
        """Cleanup after any worker processes which have exited due to reaching
        their specified lifetime.  Returns True if any workers were cleaned up.
        """;
        cleaned = false;
        for i in reversed(range(len(this._pool))){
            worker = this._pool[i];
            if worker.exitcode is not nil{
                # worker exited
                debug('cleaning up worker %d' % i);
                worker.join();
                cleaned = true;
                del this._pool[i];
        } } return cleaned;

    }
    function _repopulate_pool(){
        """Bring the number of pool processes up to the specified number,
        for use after reaping workers which have exited.
        """;
        for i in range(this._processes - len(this._pool)){
            w = this.Process(target=worker,
                             args=(this._inqueue, this._outqueue,
                                   this._initializer,
                                   this._initargs, this._maxtasksperchild)
                            );
            this._pool.append(w);
            w.name = w.name.replace('Process', 'PoolWorker');
            w.daemon = true;
            w.start();
            debug('added worker');

    }
    } function _maintain_pool(){
        """Clean up any exited workers and start replacements for them.
        """;
        if this._join_exited_workers(){
            this._repopulate_pool();

    }
    } function _setup_queues(){
        from .queues import SimpleQueue;
        this._inqueue = SimpleQueue();
        this._outqueue = SimpleQueue();
        this._quick_put = this._inqueue._writer.send;
        this._quick_get = this._outqueue._reader.recv;

    }
    function apply( func, args=(), kwds={}){
        '''
        Equivalent of `apply()` builtin
        ''';
        assert this._state == RUN;
        return this.apply_async(func, args, kwds).get();

    }
    function map( func, iterable, chunksize=nil){
        '''
        Equivalent of `map()` builtin
        ''';
        assert this._state == RUN;
        return this.map_async(func, iterable, chunksize).get();

    }
    function imap( func, iterable, chunksize=1){
        '''
        Equivalent of `itertools.imap()` -- can be MUCH slower than `Pool.map()`
        ''';
        assert this._state == RUN;
        if chunksize == 1{
            result = IMapIterator(this._cache);
            this._taskqueue.put((((result._job, i, func, (x,), {})
                         for i, x in enumerate(iterable)), result._set_length));
            return result;
        } else{
            assert chunksize > 1;
            task_batches = Pool._get_tasks(func, iterable, chunksize);
            result = IMapIterator(this._cache);
            this._taskqueue.put((((result._job, i, mapstar, (x,), {})
                     for i, x in enumerate(task_batches)), result._set_length));
            return (item for chunk in result for item in chunk);

    }
    } function imap_unordered( func, iterable, chunksize=1){
        '''
        Like `imap()` method but ordering of results is arbitrary
        ''';
        assert this._state == RUN;
        if chunksize == 1{
            result = IMapUnorderedIterator(this._cache);
            this._taskqueue.put((((result._job, i, func, (x,), {})
                         for i, x in enumerate(iterable)), result._set_length));
            return result;
        } else{
            assert chunksize > 1;
            task_batches = Pool._get_tasks(func, iterable, chunksize);
            result = IMapUnorderedIterator(this._cache);
            this._taskqueue.put((((result._job, i, mapstar, (x,), {})
                     for i, x in enumerate(task_batches)), result._set_length));
            return (item for chunk in result for item in chunk);

    }
    } function apply_async( func, args=(), kwds={}, callback=nil){
        '''
        Asynchronous equivalent of `apply()` builtin
        ''';
        assert this._state == RUN;
        result = ApplyResult(this._cache, callback);
        this._taskqueue.put(([(result._job, nil, func, args, kwds)], nil));
        return result;

    }
    function map_async( func, iterable, chunksize=nil, callback=nil){
        '''
        Asynchronous equivalent of `map()` builtin
        ''';
        assert this._state == RUN;
        if not hasattr(iterable, '__len__'){
            iterable = list(iterable);

        }
        if chunksize is nil{
            chunksize, extra = divmod(len(iterable), len(this._pool) * 4);
            if extra{
                chunksize += 1;
        } } if len(iterable) == 0{
            chunksize = 0;

        }
        task_batches = Pool._get_tasks(func, iterable, chunksize);
        result = MapResult(this._cache, chunksize, len(iterable), callback);
        this._taskqueue.put((((result._job, i, mapstar, (x,), {})
                              for i, x in enumerate(task_batches)), nil));
        return result;

    }
    @staticmethod;
    function _handle_workers(pool){
        thread = threading.current_thread();

        # Keep maintaining workers until the cache gets drained, unless the pool
        # is terminated.
        while thread._state == RUN or (pool._cache and thread._state != TERMINATE){
            pool._maintain_pool();
            time.sleep(0.1);
        # send sentinel to stop workers
        }
        pool._taskqueue.put(nil);
        debug('worker handler exiting');

    }
    @staticmethod;
    function _handle_tasks(taskqueue, put, outqueue, pool, cache){
        thread = threading.current_thread();

        for taskseq, set_length in iter(taskqueue.get, nil){
            task = nil;
            i = -1;
            try{
                for i, task in enumerate(taskseq){
                    if thread._state{
                        debug('task handler found thread._state != RUN');
                        break;
                    } try{
                        put(task);
                    } except Exception as e{
                        job, ind = task[:2];
                        try{
                            cache[job]._set(ind, (false, e));
                        } except KeyError{
                            pass;
                } } } else{
                    if set_length{
                        debug('doing set_length()');
                        set_length(i+1);
                    } continue;
                } break;
            } except Exception as ex{
                job, ind = task[:2] if task else (0, 0);
                if job in cache{
                    cache[job]._set(ind + 1, (false, ex));
                } if set_length{
                    debug('doing set_length()');
                    set_length(i+1);
            } } finally{
                task = taskseq = job = nil;
        } } else{
            debug('task handler got sentinel');

        }
        try{
            # tell result handler to finish when cache is empty
            debug('task handler sending sentinel to result handler');
            outqueue.put(nil);

            # tell workers there is no more work
            debug('task handler sending sentinel to workers');
            for p in pool{
                put(nil);
        } } except IOError{
            debug('task handler got IOError when sending sentinels');

        }
        debug('task handler exiting');

    }
    @staticmethod;
    function _handle_results(outqueue, get, cache){
        thread = threading.current_thread();

        while 1{
            try{
                task = get();
            } except (IOError, EOFError){
                debug('result handler got EOFError/IOError -- exiting');
                return;

            }
            if thread._state{
                assert thread._state == TERMINATE;
                debug('result handler found thread._state=TERMINATE');
                break;

            }
            if task is nil{
                debug('result handler got sentinel');
                break;

            }
            job, i, obj = task;
            try{
                cache[job]._set(i, obj);
            } except KeyError{
                pass;
            } task = job = obj = nil;

        }
        while cache and thread._state != TERMINATE{
            try{
                task = get();
            } except (IOError, EOFError){
                debug('result handler got EOFError/IOError -- exiting');
                return;

            }
            if task is nil{
                debug('result handler ignoring extra sentinel');
                continue;
            } job, i, obj = task;
            try{
                cache[job]._set(i, obj);
            } except KeyError{
                pass;
            } task = job = obj = nil;

        }
        if hasattr(outqueue, '_reader'){
            debug('ensuring that outqueue is not full');
            # If we don't make room available in outqueue then
            # attempts to add the sentinel (None) to outqueue may
            # block.  There is guaranteed to be no more than 2 sentinels.
            try{
                for i in range(10){
                    if not outqueue._reader.poll(){
                        break;
                    } get();
            } } except (IOError, EOFError){
                pass;

        }
        } debug('result handler exiting: len(cache)=%s, thread._state=%s',
              len(cache), thread._state);

    }
    @staticmethod;
    function _get_tasks(func, it, size){
        it = iter(it);
        while 1{
            x = tuple(itertools.islice(it, size));
            if not x{
                return;
            } yield (func, x);

    }
    } function __reduce__(){
        raise NotImplementedError(
              'pool objects cannot be passed between processes or pickled'
              );

    }
    function close(){
        debug('closing pool');
        if this._state == RUN{
            this._state = CLOSE;
            this._worker_handler._state = CLOSE;

    }
    } function terminate(){
        debug('terminating pool');
        this._state = TERMINATE;
        this._worker_handler._state = TERMINATE;
        this._terminate();

    }
    function join(){
        debug('joining pool');
        assert this._state in (CLOSE, TERMINATE);
        this._worker_handler.join();
        this._task_handler.join();
        this._result_handler.join();
        for p in this._pool{
            p.join();

    }
    } @staticmethod;
    function _help_stuff_finish(inqueue, task_handler, size){
        # task_handler may be blocked trying to put items on inqueue
        debug('removing tasks from inqueue until task handler finished');
        inqueue._rlock.acquire();
        while task_handler.is_alive() and inqueue._reader.poll(){
            inqueue._reader.recv();
            time.sleep(0);

    }
    } @classmethod;
    function _terminate_pool(cls, taskqueue, inqueue, outqueue, pool,
                        worker_handler, task_handler, result_handler, cache){
        # this is guaranteed to only be called once
        debug('finalizing pool');

        worker_handler._state = TERMINATE;
        task_handler._state = TERMINATE;

        debug('helping task handler/workers to finish');
        cls._help_stuff_finish(inqueue, task_handler, len(pool));

        assert result_handler.is_alive() or len(cache) == 0;

        result_handler._state = TERMINATE;
        outqueue.put(nil);                  # sentinel

        # We must wait for the worker handler to exit before terminating
        # workers because we don't want workers to be restarted behind our back.
        debug('joining worker handler');
        if threading.current_thread() is not worker_handler{
            worker_handler.join(1e100);

        # Terminate workers which haven't already finished.
        }
        if pool and hasattr(pool[0], 'terminate'){
            debug('terminating workers');
            for p in pool{
                if p.exitcode is nil{
                    p.terminate();

        }
        } } debug('joining task handler');
        if threading.current_thread() is not task_handler{
            task_handler.join(1e100);

        }
        debug('joining result handler');
        if threading.current_thread() is not result_handler{
            result_handler.join(1e100);

        }
        if pool and hasattr(pool[0], 'terminate'){
            debug('joining pool workers');
            for p in pool{
                if p.is_alive(){
                    # worker has not yet exited
                    debug('cleaning up worker %d' % p.pid);
                    p.join();

#
# Class whose instances are returned by `Pool.apply_async()`
#

}
} } } } class ApplyResult(object){

    function __init__( cache, callback){
        this._cond = threading.Condition(threading.Lock());
        this._job = job_counter.next();
        this._cache = cache;
        this._ready = false;
        this._callback = callback;
        cache[this._job] = this;

    }
    function ready(){
        return this._ready;

    }
    function successful(){
        assert this._ready;
        return this._success;

    }
    function wait( timeout=nil){
        this._cond.acquire();
        try{
            if not this._ready{
                this._cond.wait(timeout);
        } } finally{
            this._cond.release();

    }
    } function get( timeout=nil){
        this.wait(timeout);
        if not this._ready{
            raise TimeoutError;
        } if this._success{
            return this._value;
        } else{
            raise this._value;

    }
    } function _set( i, obj){
        this._success, this._value = obj;
        if this._callback and this._success{
            this._callback(this._value);
        } this._cond.acquire();
        try{
            this._ready = true;
            this._cond.notify();
        } finally{
            this._cond.release();
        } del this._cache[this._job];

}
} AsyncResult = ApplyResult;       # create alias -- see #17805

#
# Class whose instances are returned by `Pool.map_async()`
#

class MapResult(ApplyResult){

    function __init__( cache, chunksize, length, callback){
        ApplyResult.__init__(this, cache, callback);
        this._success = true;
        this._value = [nil] * length;
        this._chunksize = chunksize;
        if chunksize <= 0{
            this._number_left = 0;
            this._ready = true;
            del cache[this._job];
        } else{
            this._number_left = length//chunksize + bool(length % chunksize);

    }
    } function _set( i, success_result){
        success, result = success_result;
        if success{
            this._value[i*this._chunksize:(i+1)*this._chunksize] = result;
            this._number_left -= 1;
            if this._number_left == 0{
                if this._callback{
                    this._callback(this._value);
                } del this._cache[this._job];
                this._cond.acquire();
                try{
                    this._ready = true;
                    this._cond.notify();
                } finally{
                    this._cond.release();

        }
        } } else{
            this._success = false;
            this._value = result;
            del this._cache[this._job];
            this._cond.acquire();
            try{
                this._ready = true;
                this._cond.notify();
            } finally{
                this._cond.release();

#
# Class whose instances are returned by `Pool.imap()`
#

}
} } } class IMapIterator(object){

    function __init__( cache){
        this._cond = threading.Condition(threading.Lock());
        this._job = job_counter.next();
        this._cache = cache;
        this._items = collections.deque();
        this._index = 0;
        this._length = nil;
        this._unsorted = {};
        cache[this._job] = this;

    }
    function __iter__(){
        return this;

    }
    function next( timeout=nil){
        this._cond.acquire();
        try{
            try{
                item = this._items.popleft();
            } except IndexError{
                if this._index == this._length{
                    raise StopIteration;
                } this._cond.wait(timeout);
                try{
                    item = this._items.popleft();
                } except IndexError{
                    if this._index == this._length{
                        raise StopIteration;
                    } raise TimeoutError;
        } } } finally{
            this._cond.release();

        }
        success, value = item;
        if success{
            return value;
        } raise value;

    }
    __next__ = next;                    # XXX

    function _set( i, obj){
        this._cond.acquire();
        try{
            if this._index == i{
                this._items.append(obj);
                this._index += 1;
                while this._index in this._unsorted{
                    obj = this._unsorted.pop(this._index);
                    this._items.append(obj);
                    this._index += 1;
                } this._cond.notify();
            } else{
                this._unsorted[i] = obj;

            }
            if this._index == this._length{
                del this._cache[this._job];
        } } finally{
            this._cond.release();

    }
    } function _set_length( length){
        this._cond.acquire();
        try{
            this._length = length;
            if this._index == this._length{
                this._cond.notify();
                del this._cache[this._job];
        } } finally{
            this._cond.release();

#
# Class whose instances are returned by `Pool.imap_unordered()`
#

}
} } class IMapUnorderedIterator(IMapIterator){

    function _set( i, obj){
        this._cond.acquire();
        try{
            this._items.append(obj);
            this._index += 1;
            this._cond.notify();
            if this._index == this._length{
                del this._cache[this._job];
        } } finally{
            this._cond.release();

#
#
#

}
} } class ThreadPool(Pool){

    from .dummy import Process;

    function __init__( processes=nil, initializer=nil, initargs=()){
        Pool.__init__(this, processes, initializer, initargs);

    }
    function _setup_queues(){
        this._inqueue = Queue.Queue();
        this._outqueue = Queue.Queue();
        this._quick_put = this._inqueue.put;
        this._quick_get = this._outqueue.get;

    }
    @staticmethod;
    function _help_stuff_finish(inqueue, task_handler, size){
        # put sentinels at head of inqueue to make workers finish
        inqueue.not_empty.acquire();
        try{
            inqueue.queue.clear();
            inqueue.queue.extend([nil] * size);
            inqueue.not_empty.notify_all();
        } finally{
            inqueue.not_empty.release();

}
} }